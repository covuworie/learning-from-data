{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import sys\n",
    "\n",
    "# Follow instructions here to get cvxopt working. --- painful!!! \n",
    "#https://stackoverflow.com/questions/46009925/how-to-install-cvxopt-on-on-windows-10-on-python-3-6\n",
    "from cvxopt import matrix, solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common code for questions 7-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training and testing data in pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    column_names = ['digit', 'intensity', 'symmetry']\n",
    "    sep = '\\s+'\n",
    "    features_train = pd.read_table('http://www.amlbook.com/data/zip/features.train', sep=sep, names=column_names)\n",
    "    features_test = pd.read_table('http://www.amlbook.com/data/zip/features.test', sep=sep, names=column_names)\n",
    "    return features_train, features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set output labels for classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_one_vs_all = dict(\n",
    "    {'zero_vs_all': 0,\n",
    "     'one_vs_all': 1,\n",
    "     'two_vs_all': 2,\n",
    "     'three_vs_all': 3,\n",
    "     'four_vs_all': 4,\n",
    "     'five_vs_all': 5,\n",
    "     'six_vs_all': 6,\n",
    "     'seven_vs_all': 7,\n",
    "     'eight_vs_all': 8,\n",
    "     'nine_vs_all': 9\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_one_vs_five = {'one_vs_five': [1,5]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create one-versus-all and one-versus-five dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_vs_all_dataframe(df, classifiers):\n",
    "    # add binary labels to dataframe\n",
    "    one_vs_all = pd.DataFrame(df, copy=True)\n",
    "    for class_label, digit in classifiers.items():\n",
    "        labels = one_vs_all.loc[one_vs_all['digit'] == digit, 'digit']\n",
    "        labels.loc[:] = 1.0\n",
    "        one_vs_all[class_label] = labels\n",
    "        \n",
    "    one_vs_all.fillna(-1.0, inplace=True)\n",
    "    return one_vs_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_one_vs_all = create_one_vs_all_dataframe(features_train, classifiers_one_vs_all)\n",
    "features_test_one_vs_all = create_one_vs_all_dataframe(features_test, classifiers_one_vs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_vs_one_dataframe(df, classifiers):\n",
    "    # add binary labels to dataframe  \n",
    "    for class_label in classifiers.keys():\n",
    "        digits = classifiers[class_label]\n",
    "        one_vs_one = pd.DataFrame(df.loc[df['digit'].isin(digits),:], copy=True)\n",
    "        for digit in digits:\n",
    "            labels = one_vs_one.loc[one_vs_one['digit'] == digit, 'digit']\n",
    "            labels.loc[:] = 1.0\n",
    "            one_vs_one[class_label] = labels\n",
    "            break\n",
    "        \n",
    "    one_vs_one.fillna(-1.0, inplace=True)\n",
    "    return one_vs_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_one_vs_five = create_one_vs_one_dataframe(features_train, classifiers_one_vs_five)\n",
    "features_test_one_vs_five = create_one_vs_one_dataframe(features_test, classifiers_one_vs_five)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dataset (inputs / outputs) for a specific classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(df, class_label):\n",
    "    inputs = np.array(df.loc[:, ['intensity', 'symmetry']])\n",
    "    outputs = np.array(df.loc[:, class_label])\n",
    "    data = np.column_stack((inputs, outputs))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of regularized least-squares linear regression for classiﬁcation that minimizes:\n",
    "\n",
    "$$\\frac{1}{N}\\sum_{n=1}^{N}(\\textbf{w}^{T}\\textbf{z}_{n}-y_{n})^{2}+\\frac{\\lambda}{N}\\textbf{w}^{T}\\textbf{w}$$\n",
    "\n",
    "where $\\textbf{w}$ includes $w_{0}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    \"\"\" Class that performs regularized least-squares linear regression for classification. \"\"\"\n",
    "    \n",
    "    def __init__(self, transform=False):\n",
    "        \"\"\" Create a Linear Regression Algorithm. \n",
    "        Args:\n",
    "        transform (bool): If True, apply a feature transform z = (1, x1, x2, x1.x2, x1^2, x2^2) to the inputs (x1, x2)\n",
    "                          Otherwise, use inputs as they are so z = (1, x1, x2)\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "    \n",
    "    def fit(self, inputs, outputs, llambda=1.0):    \n",
    "        \"\"\"Fit the training data using the regularized least-squares linear regression learning algorithm\n",
    "        Args:\n",
    "        inputs (np.ndarray): Inputs\n",
    "        outputs (np.ndarray): Outputs\n",
    "        llambda (float): Regularization parameter\n",
    "        Returns:\n",
    "        np.ndarray: Weights\n",
    "        \"\"\"      \n",
    "        # get inputs and outputs\n",
    "        Z = self.transform_inputs(inputs)\n",
    "        y = outputs\n",
    "        \n",
    "        # linear regression solution with regularization\n",
    "        Z_trans = np.transpose(Z)\n",
    "        normZ = np.matmul(Z_trans, Z)  \n",
    "        I = np.identity(np.size(normZ, axis=0))\n",
    "        weights = np.matmul(np.linalg.inv(np.add(normZ, llambda * I)), np.matmul(Z_trans, y))\n",
    "        return weights\n",
    "    \n",
    "    def binary_error(self, weights, inputs, outputs):    \n",
    "        \"\"\"Compute binary classification error of sample\n",
    "        Args:\n",
    "        weights (np.ndarray): Weights of hypothesis\n",
    "        inputs (np.ndarray): Inputs\n",
    "        outputs (np.ndarray): Outputs\n",
    "        Returns:\n",
    "        float: Binary classification error (fraction of misclassified points in the sample)\n",
    "        \"\"\"\n",
    "        Z = self.transform_inputs(inputs)\n",
    "        y = outputs\n",
    "        \n",
    "        g = [np.sign(np.dot(weights.T, z)) for z in Z]\n",
    "        return sum(g != y) / len(y)        \n",
    "         \n",
    "    # privates\n",
    "    def transform_inputs(self, inputs):\n",
    "        ones = np.ones(len(inputs)).reshape(len(inputs), 1)\n",
    "        x1 = inputs[:, 0].reshape(len(inputs), 1)\n",
    "        x2 = inputs[:, 1].reshape(len(inputs), 1)\n",
    "        \n",
    "        if self.transform:\n",
    "            return np.concatenate((ones, x1, x2, x1*x2, x1**2, x2**2), axis=1)\n",
    "        else:\n",
    "            return np.concatenate((ones, x1, x2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute in-sample and out-of-sample errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_out_sample_errors(classifiers, features_train, features_test=pd.DataFrame(), llambda=1.0, transform=False):\n",
    "    results = []\n",
    "    \n",
    "    for class_label in classifiers.keys():\n",
    "            # get training data\n",
    "            dataset_train = get_dataset(features_train, class_label)\n",
    "            inputs_train = dataset_train[:, 0:2]\n",
    "            outputs_train = dataset_train[:, 2]\n",
    "            \n",
    "            # fit the model\n",
    "            lr = LinearRegression(transform)\n",
    "            weights = lr.fit(inputs_train, outputs_train, llambda)\n",
    "            \n",
    "            # compute in-sample error\n",
    "            error_in_sample = lr.binary_error(weights, inputs_train, outputs_train)\n",
    "            \n",
    "            # get testing data\n",
    "            error_out_sample = None\n",
    "            if not features_test.empty:\n",
    "                dataset_test = get_dataset(features_test, class_label)\n",
    "                inputs_test = dataset_test[:, 0:2]\n",
    "                outputs_test = dataset_test[:, 2]\n",
    "                \n",
    "                # compute out-of-sample error\n",
    "                error_out_sample =  lr.binary_error(weights, inputs_test, outputs_test)\n",
    "            \n",
    "            # add to results\n",
    "            result = {'classifier': class_label,\n",
    "                      'transform': transform,\n",
    "                      'lambda': llambda,\n",
    "                      'ein': error_in_sample,\n",
    "                      'eout': error_out_sample}\n",
    "            results.append(result)\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_binary_errors(results, print_classifiers=None, print_errors='both'):   \n",
    "    if print_errors not in ['ein', 'eout', 'both']:\n",
    "        raise ValueError('\"print_errors\" must either \"ein\", \"eout\" or \"both\"')\n",
    "    \n",
    "    for result in results:\n",
    "        if isinstance(print_classifiers, list) and result['classifier'] not in print_classifiers:\n",
    "            continue\n",
    "        \n",
    "        if print_errors == 'ein':\n",
    "            print('For transform = {0} and λ = {1}, the \"{2}\" classifier in-sample error Ein = {3}'\n",
    "                  .format(result['transform'], result['lambda'], result['classifier'], round(result['ein'], 3)))\n",
    "        elif print_errors == 'eout':\n",
    "            print('For transform = {0} and λ = {1}, the \"{2}\" classifier in-sample error Eout = {3}'\n",
    "                  .format(result['transform'], result['lambda'], result['classifier'], round(result['eout'], 3)))\n",
    "        elif print_errors == 'both':\n",
    "            print('For transform = {0} and λ = {1}, the \"{2}\" classifier in-sample error Ein = {3} '\n",
    "                  'and the out-of-sample-error Eout = {4}'\n",
    "                  .format(result['transform'], result['lambda'], result['classifier'], \n",
    "                          round(result['ein'], 3), round(result['eout'], 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Compute in-sample error for 5-versus-all through to 9-versus-all classifier for $\\lambda$ = 1 without a feature transform $z = x = (1, x_{1}, x_{2})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = in_out_sample_errors(classifiers_one_vs_all, features_train_one_vs_all, llambda=1.0, transform=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For transform = False and λ = 1.0, the \"five_vs_all\" classifier in-sample error Ein = 0.076\n",
      "For transform = False and λ = 1.0, the \"six_vs_all\" classifier in-sample error Ein = 0.091\n",
      "For transform = False and λ = 1.0, the \"seven_vs_all\" classifier in-sample error Ein = 0.088\n",
      "For transform = False and λ = 1.0, the \"eight_vs_all\" classifier in-sample error Ein = 0.074\n",
      "For transform = False and λ = 1.0, the \"nine_vs_all\" classifier in-sample error Ein = 0.088\n"
     ]
    }
   ],
   "source": [
    "print_binary_errors(results, print_classifiers=['five_vs_all', \n",
    "                                                'six_vs_all', \n",
    "                                                'seven_vs_all', \n",
    "                                                'eight_vs_all', \n",
    "                                                'nine_vs_all'],\n",
    "                    print_errors='ein')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Compute out-of-sample error for 0-versus-all through to 4-versus-all classifier for $\\lambda$ = 1 with a feature transform $z = (1, x_{1}, x_{2}, x_{1}x_{2}, x_{1}^2, x_{2}^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = in_out_sample_errors(classifiers_one_vs_all, features_train_one_vs_all, features_test_one_vs_all, llambda=1.0, \n",
    "                               transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For transform = True and λ = 1.0, the \"zero_vs_all\" classifier in-sample error Eout = 0.107\n",
      "For transform = True and λ = 1.0, the \"one_vs_all\" classifier in-sample error Eout = 0.022\n",
      "For transform = True and λ = 1.0, the \"two_vs_all\" classifier in-sample error Eout = 0.099\n",
      "For transform = True and λ = 1.0, the \"three_vs_all\" classifier in-sample error Eout = 0.083\n",
      "For transform = True and λ = 1.0, the \"four_vs_all\" classifier in-sample error Eout = 0.1\n"
     ]
    }
   ],
   "source": [
    "print_binary_errors(results, print_classifiers=['zero_vs_all', \n",
    "                                                'one_vs_all', \n",
    "                                                'two_vs_all', \n",
    "                                                'three_vs_all', \n",
    "                                                'four_vs_all'],\n",
    "                    print_errors='eout')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Compare the in-sample and out-of-sample errors for 0-versus-all through to 9-versus-all classifier for $\\lambda$ = 1 with and without the feature transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = in_out_sample_errors(classifiers_one_vs_all, features_train_one_vs_all, features_test_one_vs_all, llambda=1.0, \n",
    "                               transform=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For transform = False and λ = 1.0, the \"zero_vs_all\" classifier in-sample error Ein = 0.109 and the out-of-sample-error Eout = 0.115\n",
      "For transform = False and λ = 1.0, the \"one_vs_all\" classifier in-sample error Ein = 0.015 and the out-of-sample-error Eout = 0.022\n",
      "For transform = False and λ = 1.0, the \"two_vs_all\" classifier in-sample error Ein = 0.1 and the out-of-sample-error Eout = 0.099\n",
      "For transform = False and λ = 1.0, the \"three_vs_all\" classifier in-sample error Ein = 0.09 and the out-of-sample-error Eout = 0.083\n",
      "For transform = False and λ = 1.0, the \"four_vs_all\" classifier in-sample error Ein = 0.089 and the out-of-sample-error Eout = 0.1\n",
      "For transform = False and λ = 1.0, the \"five_vs_all\" classifier in-sample error Ein = 0.076 and the out-of-sample-error Eout = 0.08\n",
      "For transform = False and λ = 1.0, the \"six_vs_all\" classifier in-sample error Ein = 0.091 and the out-of-sample-error Eout = 0.085\n",
      "For transform = False and λ = 1.0, the \"seven_vs_all\" classifier in-sample error Ein = 0.088 and the out-of-sample-error Eout = 0.073\n",
      "For transform = False and λ = 1.0, the \"eight_vs_all\" classifier in-sample error Ein = 0.074 and the out-of-sample-error Eout = 0.083\n",
      "For transform = False and λ = 1.0, the \"nine_vs_all\" classifier in-sample error Ein = 0.088 and the out-of-sample-error Eout = 0.088\n"
     ]
    }
   ],
   "source": [
    "print_binary_errors(results, print_errors='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = in_out_sample_errors(classifiers_one_vs_all, features_train_one_vs_all, features_test_one_vs_all, llambda=1.0, \n",
    "                               transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For transform = True and λ = 1.0, the \"zero_vs_all\" classifier in-sample error Ein = 0.102 and the out-of-sample-error Eout = 0.107\n",
      "For transform = True and λ = 1.0, the \"one_vs_all\" classifier in-sample error Ein = 0.012 and the out-of-sample-error Eout = 0.022\n",
      "For transform = True and λ = 1.0, the \"two_vs_all\" classifier in-sample error Ein = 0.1 and the out-of-sample-error Eout = 0.099\n",
      "For transform = True and λ = 1.0, the \"three_vs_all\" classifier in-sample error Ein = 0.09 and the out-of-sample-error Eout = 0.083\n",
      "For transform = True and λ = 1.0, the \"four_vs_all\" classifier in-sample error Ein = 0.089 and the out-of-sample-error Eout = 0.1\n",
      "For transform = True and λ = 1.0, the \"five_vs_all\" classifier in-sample error Ein = 0.076 and the out-of-sample-error Eout = 0.079\n",
      "For transform = True and λ = 1.0, the \"six_vs_all\" classifier in-sample error Ein = 0.091 and the out-of-sample-error Eout = 0.085\n",
      "For transform = True and λ = 1.0, the \"seven_vs_all\" classifier in-sample error Ein = 0.088 and the out-of-sample-error Eout = 0.073\n",
      "For transform = True and λ = 1.0, the \"eight_vs_all\" classifier in-sample error Ein = 0.074 and the out-of-sample-error Eout = 0.083\n",
      "For transform = True and λ = 1.0, the \"nine_vs_all\" classifier in-sample error Ein = 0.088 and the out-of-sample-error Eout = 0.088\n"
     ]
    }
   ],
   "source": [
    "print_binary_errors(results, print_errors='both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "Compare the in-sample and out-of-sample errors for 0-versus-all through to 9-versus-all classifier for λ = 1.0 and λ = 0.01 with feature transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = in_out_sample_errors(classifiers_one_vs_five, features_train_one_vs_five, features_test_one_vs_five, llambda=1.0, \n",
    "                               transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For transform = True and λ = 1.0, the \"one_vs_five\" classifier in-sample error Ein = 0.005 and the out-of-sample-error Eout = 0.026\n"
     ]
    }
   ],
   "source": [
    "print_binary_errors(results, print_errors='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = in_out_sample_errors(classifiers_one_vs_five, features_train_one_vs_five, features_test_one_vs_five, llambda=0.01, \n",
    "                               transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For transform = True and λ = 0.01, the \"one_vs_five\" classifier in-sample error Ein = 0.004 and the out-of-sample-error Eout = 0.028\n"
     ]
    }
   ],
   "source": [
    "print_binary_errors(results, print_errors='both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common code for questions 11-12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_set():\n",
    "    return np.array([1., 0., -1.,\n",
    "                     0., 1., -1.,\n",
    "                     0., -1., -1.,\n",
    "                     -1., 0., 1.,\n",
    "                     0., 2., 1.,\n",
    "                     0., -2., 1.,\n",
    "                     -2., 0., 1.]).reshape(7, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_training_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(features, label, features_names=['$x_{1}$', '$x_{2}$'], plot_hyperplanes=False):\n",
    "    plt.scatter(features[:, 0], features[:, 1], c=label, cmap='rainbow');\n",
    "    plt.xlabel(features_names[0]);\n",
    "    plt.ylabel(features_names[1]);\n",
    "    \n",
    "    if plot_hyperplanes:\n",
    "        eps = 1e-12 # to prevent divide by zero\n",
    "        xfit = np.linspace(-3.5, 3.5)\n",
    "        \n",
    "        for w1, w2, b in [(-1., 1., -0.5), (1., -1., -0.5), (1., 0., -0.5), (0., 1., -0.5)]:\n",
    "            slope = -w1 / (w2+eps)\n",
    "            intercept = -b / (w2+eps)\n",
    "            yfit =  slope * xfit + intercept\n",
    "            plt.plot(xfit, yfit, label=\"w1 = {0}, w2 = {1}, b = {2}\".format(str(w1), str(w2), str(b)))\n",
    "            plt.legend(loc='upper left')\n",
    "        \n",
    "        plt.xlim(-3.5, 3.5);\n",
    "        plt.ylim(-3.5, 5.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the data is not linearly separable in the $\\mathcal{X}$ space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ca23489ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data(train_data[:, 0:2], train_data[:, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform this training set into another two-dimensional space $\\mathcal{Z}$\n",
    "\n",
    "$$z_{1}=x_{2}^{2}-2x_{1}-1\\qquad z_{2}=x_{1}^{2}-2x_{2}+1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_inputs(inputs):\n",
    "    x1 = inputs[:, 0].reshape(len(inputs), 1)\n",
    "    x2 = inputs[:, 1].reshape(len(inputs), 1)\n",
    "    return np.concatenate((x2**2 - 2*x1 - 1, x1**2 - 2*x2 + 1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = transform_inputs(train_data[:, 0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the data is now linearly separable in the $\\mathcal{Z}$ space (the last two points map on to the same point (3, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ca253bea90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data(train_inputs[:, 0:2], train_data[:, 2], features_names=['$z_{1}$', '$z_{2}$'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of hard-margin Support Vector Machines (SVM) classification learning algorithm using the kernel:\n",
    "\n",
    "$$K(x,x')=(1+\\textbf{x}_{T}\\textbf{x}')^{2}$$\n",
    "\n",
    "which corresponds to a second-order polynomial transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    \"\"\" Class that performs hard-margin Support Vector Machines (SVM) classification using polynomial kernel of degree 2. \"\"\"\n",
    "    def __init__(self, kernel='poly', Q=2, gamma=1.0):\n",
    "        \"\"\" Create a Support Vector Machine Algorithm (SVM). \n",
    "        Args:\n",
    "        kernel (string): Kernel to use, \"poly\" (polynomial) or \"rbf\" (radial basis function)\n",
    "        Q (int): Degree of the polynomial kernel (Q >= 0)\n",
    "        gamma (float): Constant in the RBF kernel\n",
    "        \"\"\"\n",
    "        if kernel not in ['poly','rbf']:\n",
    "            raise ValueError('Kernel must be \"poly\" or \"rbf\".')\n",
    "        \n",
    "        self.kernel = kernel\n",
    "        self.Q = Q\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def fit(self, inputs, outputs):\n",
    "        \"\"\"Fit the training data using the hard-margin Support Vector Machines (SVM) learning algorithm.\n",
    "        Args:\n",
    "        inputs (np.ndarray): Input points.\n",
    "        outputs (np.ndarray): Targets.\n",
    "        Returns:\n",
    "        Tuple(np.ndarray, np.ndarray, np.ndarray, float): alphas, support vectors, support vector outputs, b\n",
    "        \"\"\" \n",
    "        xn = inputs\n",
    "        yn = outputs\n",
    "        N = len(xn)\n",
    "        \n",
    "        mat = []\n",
    "        for row_idx in range(0, N):\n",
    "            for col_idx in range(0, N):\n",
    "                if self.kernel == 'poly':\n",
    "                    kernel = self.kernel_poly(xn[row_idx], xn[col_idx])\n",
    "                elif self.kernel == 'rbf':\n",
    "                    kernel = self.kernel_rbf(xn[row_idx], xn[col_idx])\n",
    "                val = yn[row_idx] * yn[col_idx] * kernel\n",
    "                mat.append(val)\n",
    "        mat = np.array(mat).reshape((N, N))\n",
    "        \n",
    "        # form matrices for quadratic programming solver\n",
    "        dim = len(xn[0])\n",
    "        P = matrix(mat, tc='d')\n",
    "        q = matrix(-np.ones(N), tc='d')\n",
    "        b = matrix(0.0, tc='d')\n",
    "        A = matrix(yn, tc='d')\n",
    "        A = A.trans()\n",
    "        G = matrix(-np.identity(N), tc='d')\n",
    "        h = matrix(np.zeros(N), tc='d')\n",
    "        \n",
    "        #print('P = ', P)\n",
    "        #print('q = ', q)\n",
    "        #print('G = ', G)\n",
    "        #print('h = ', h)\n",
    "        #print('A = ', A)\n",
    "        #print('b = ', b)\n",
    "                \n",
    "        # call qp solver to compute weights\n",
    "        solvers.options['show_progress'] = False # supress solver output\n",
    "        \n",
    "        sol = solvers.qp(P, q, G, h, A, b)\n",
    "        alpha = np.array(list(sol['x']))\n",
    "        #print('alpha = ', sol['x'])\n",
    "        \n",
    "        weights = np.zeros(dim)\n",
    "        sv = []\n",
    "        sv_alphas = []\n",
    "        sv_outputs = []\n",
    "        for n in range(0, N):\n",
    "            if alpha[n] > 1e-5: # => xn[n] is support vector\n",
    "                sv.append(xn[n])\n",
    "                sv_alphas.append(alpha[n])\n",
    "                sv_outputs.append(yn[n])\n",
    "                    \n",
    "        # compute number of support vectors \n",
    "        num_sv = len(sv)\n",
    "        if (num_sv == 0):\n",
    "            raise Exception('There are no support vectors.')\n",
    "        \n",
    "        bs = []\n",
    "        for m in range(0, num_sv):\n",
    "            b = sv_outputs[m]\n",
    "            for n in range(0, num_sv):\n",
    "                if self.kernel == 'poly':\n",
    "                    kernel = self.kernel_poly(sv[n], sv[m])\n",
    "                elif self.kernel == 'rbf':\n",
    "                    kernel = self.kernel_rbf(sv[n], sv[m])\n",
    "                b -= sv_alphas[n] * sv_outputs[n] * kernel\n",
    "            bs.append(b)\n",
    "                \n",
    "        bs_round = np.round(bs, 1)\n",
    "        #print('bs sv = ', bs)\n",
    "        \n",
    "        #print('bs = ', bs)\n",
    "        #print('bs_round = ', bs_round)\n",
    "        #print('np.unique(bs_round) = ', np.unique(bs_round))\n",
    "        \n",
    "        #if (len(np.unique(bs_round)) != 1):\n",
    "        #    raise Exception('All support vectors must produce the same value of b.')\n",
    "            \n",
    "        weights = np.insert(weights, 0, b)\n",
    "        #print('weights = ', weights)\n",
    "\n",
    "        return np.array(sv_alphas), np.array(sv), np.array(sv_outputs), b\n",
    "    \n",
    "    def binary_error(self, sv_alphas, sv, sv_outputs, b, inputs, outputs):\n",
    "        \"\"\" Evaluate binary classification error. \n",
    "        Args:\n",
    "        sv_alphas (np.ndarray): Support vector Lagrange multipliers.\n",
    "        sv (np.ndarray): Support vectors.\n",
    "        sv_outputs (np.ndarray): Support vector outputs.\n",
    "        b (float): Constant.\n",
    "        inputs (np.ndarray): Inputs.\n",
    "        outputs (np.ndarray): Outputs.\n",
    "        Returns (float): Binary classification error percentage\n",
    "        \"\"\"\n",
    "        x = inputs\n",
    "        y = outputs\n",
    "        num_sv = len(sv)\n",
    "        \n",
    "        gs = []\n",
    "        for xm in x:\n",
    "            signal = 0.0\n",
    "            for n in range(0, num_sv):\n",
    "                if self.kernel == 'poly':\n",
    "                    kernel = self.kernel_poly(sv[n], xm)\n",
    "                elif self.kernel == 'rbf':\n",
    "                    kernel = self.kernel_rbf(sv[n], xm)\n",
    "                signal += sv_alphas[n] * sv_outputs[n] * kernel\n",
    "            signal += b\n",
    "            gs.append(signal)\n",
    "                \n",
    "        g = np.array(np.sign(gs))\n",
    "        return 100. * np.sum(y != g) / len(y)   \n",
    "    \n",
    "    # privates\n",
    "    def kernel_poly(self, xn, xm):\n",
    "        return (1.0 + np.dot(xn.T, xm))**self.Q\n",
    "    \n",
    "    def kernel_rbf(self, xn, xm):\n",
    "        return np.exp(-self.gamma * (np.linalg.norm(xn - xm)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the hyperplane is described by the equation, $\\textbf{w}^{T}\\textbf{z} + b = 0$, we can now plot the hyperplanes given by the values of $w_{1}$, $w_{2}$, b: \n",
    "- [-1, 1, 0.5]\n",
    "- [1, -1, -0.5]\n",
    "- [1, 0, -0.5]\n",
    "- [0, 1, -0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ca254d4b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data(train_inputs[:, 0:2], train_data[:, 2], features_names=['$z_{1}$', '$z_{2}$'], plot_hyperplanes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can see that the red hyperplane ($w_{1} = 1.0, w_{2} = 0.0, b = -0.5$) is the only one that separates the data and as expected it is orthogonal to the weight vector $w = [1.0, 0.0]$. Furthermore, by inspection we can see that it separates the data with the maximum margin (as it bisects the closest points of the two classes), and that margin is 1.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of support vectors is 5\n"
     ]
    }
   ],
   "source": [
    "svm = SVM()\n",
    "alphas, support_vectors, outputs, b = svm.fit(train_data[:, 0:2], train_data[:, 2])\n",
    "print('The number of support vectors is', len(support_vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radial Basis Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common code for questions 13-18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We experiment with the RBF model, both in regular form (Lloyd + pseudo-inverse) with K centers:\n",
    "\n",
    "$$sign\\Bigg( \\sum_{k=1}^{K} w_{k}\\exp(- \\gamma \\Vert x - \\mu_{k} \\Vert)^{2} + b \\Bigg)$$\n",
    "\n",
    "(notice that there is a bias term), and in kernel form (using the RBF kernel in hardmargin SVM):\n",
    "\n",
    "$$sign\\Bigg( \\sum_{\\alpha_{n}\\gt 0} \\alpha_{n}y_n\\exp(- \\gamma \\Vert x - x_{n} \\Vert)^{2} + b \\Bigg)$$\n",
    "\n",
    "The input space is X = [−1,1]×[−1,1] with uniform probability distribution, and the target is\n",
    "\n",
    "$$f(x)=sign(x_{2}-x_{1}+0.25 \\sin(\\pi x_{1}))$$\n",
    "\n",
    "which is slightly nonlinear in the X space. In each run, generate 100 training points at random using this target, and apply both forms of RBF to these training points. \n",
    "\n",
    "Here are some guidelines: \n",
    "\n",
    "- Repeat the experiment for as many runs as needed to get the answer to be stable (statistically away from ﬂipping to the closest competing answer). \n",
    "\n",
    "- In case a data set is not separable in the ‘Z space’ by the RBF kernel using hardmargin SVM, discard the run but keep track of how often this happens, if ever.\n",
    "\n",
    "- When you use Lloyd’s algorithm, initialize the centers to random points in X and iterate until there is no change from iteration to iteration. If a cluster becomes empty, discard the run and repeat.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate training inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_inputs(N=100):\n",
    "    return np.array([np.random.uniform(-1.0, 1.0, 2) for n in range(0, N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate training targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_targets(inputs):\n",
    "    x1 = inputs[:, 0]\n",
    "    x2 = inputs[:, 1]\n",
    "    return np.sign(x1 - x2 + 0.25 * np.sin(np.pi * x1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run SVM trials with RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_svm_trials(N=100, n_trials=100, gamma=1.5):\n",
    "    ein = 0.\n",
    "    non_sep_count = 0\n",
    "    \n",
    "    for n_trial in range(0, n_trials):\n",
    "        train_inputs = generate_training_inputs(N)\n",
    "        train_outputs = compute_targets(train_inputs)\n",
    "        \n",
    "        svm = SVM(kernel='rbf', gamma=gamma)\n",
    "        alphas, sv, sv_outputs, b = svm.fit(train_inputs, train_outputs)\n",
    "        ein += svm.binary_error(alphas, sv, sv_outputs, b, train_inputs, train_outputs)\n",
    "        \n",
    "        if ein > 0.0:\n",
    "            non_sep_count += 1\n",
    "    \n",
    "    return non_sep_count / n_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KKMeans:\n",
    "    \"\"\" Class that performs K-means clustering using Lloyd's algorithm. \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def fit(inputs, K=3, n_runs = 1, max_iter=300, tol=0.0001):\n",
    "        \"\"\" Cluster inputs into K clusters using Lloyd's algorithm. \n",
    "        Args:\n",
    "        inputs (np.ndarray): Inputs.\n",
    "        K (int): Number of clusters.\n",
    "        n_runs (int): Number of times to run Lloyd's algorithm (it falls into local minima)\n",
    "        max_iter (int): Maximum number of iterations\n",
    "        tol (float): Convergence tolerance\n",
    "        Returns Tuple(np.ndarray, np.ndarray): Centroids of clusters (μ1, ..., μk) and cluster labels of inputs\n",
    "        \"\"\"\n",
    "        run_cluster_labels = []\n",
    "        run_centroids = []\n",
    "        \n",
    "        for run in range(0, n_runs):\n",
    "            \n",
    "            # initialize K centroids at random (note we could also initialize clusters instead)\n",
    "            centroids = generate_training_inputs(K)\n",
    "\n",
    "            min_distance = sys.float_info.max\n",
    "            for iteration in range(0, max_iter):\n",
    "\n",
    "                # assign inputs to cluster with closest centroid\n",
    "                cluster_labels = []\n",
    "                for inputt in inputs:\n",
    "                    distances = []\n",
    "                    for centroid in centroids:\n",
    "                        distance = np.linalg.norm(inputt - centroid)\n",
    "                        distances.append(distance)\n",
    "                    cluster_num = np.argmin(distances)\n",
    "                    cluster_labels.append(cluster_num)\n",
    "                    #print(\"{0} assigned to cluster {1}\".format(inputt, cluster_num))\n",
    "                #print('cluster labels = ', cluster_labels)\n",
    "\n",
    "                # if a cluster is empty discard the run\n",
    "                if set(cluster_labels) != set(range(0, K)):\n",
    "                    return (np.array([]), np.array([]))\n",
    "\n",
    "                prev_centroids = centroids\n",
    "\n",
    "                # compute cluster centroids\n",
    "                centroids = []\n",
    "                for cluster_label in range(0, K):\n",
    "                    input_idxs = [i for i, label in enumerate(cluster_labels) if label == cluster_label]\n",
    "                    #print('indices = ', input_idxs)\n",
    "                    mean_cluster = np.mean(inputs[input_idxs], axis=0)\n",
    "                    #print('mean cluster = ', mean_cluster)\n",
    "                    centroids.append(mean_cluster)              \n",
    "                centroids = np.array(centroids)\n",
    "\n",
    "                #print('iteration = ', iteration+1)\n",
    "\n",
    "                # check for convergence\n",
    "                #print('prev_centroids = ', prev_centroids)\n",
    "                #print('centroids = ', centroids)\n",
    "                if iteration > 0: \n",
    "                    if np.linalg.norm(prev_centroids - centroids) < tol and prev_cluster_labels == cluster_labels:\n",
    "                        #print('Converged')\n",
    "                        break\n",
    "\n",
    "                prev_cluster_labels = cluster_labels\n",
    "                \n",
    "            run_centroids.append(centroids)\n",
    "            run_cluster_labels.append(cluster_labels)\n",
    "            \n",
    "        high_count_index = KKMeans.arg_max_run_clusters(run_cluster_labels, K, n_runs)\n",
    "        \n",
    "        return run_centroids[high_count_index], np.array(run_centroids[high_count_index])\n",
    "    \n",
    "    # privates\n",
    "    @staticmethod\n",
    "    def arg_max_run_clusters(run_cluster_labels, K, n_runs):\n",
    "        counts = {}\n",
    "        run_clusters = []\n",
    "        for run in range(0, len(run_cluster_labels)):\n",
    "            run_cluster = []\n",
    "            for k in range(0, K):\n",
    "                indices = [i for i, x in enumerate(run_cluster_labels[run]) if x == k]\n",
    "                run_cluster.append(indices)\n",
    "            run_cluster.sort()\n",
    "\n",
    "            if run_cluster not in run_clusters:\n",
    "                run_clusters.append(run_cluster)\n",
    "                counts[run] = 1\n",
    "            else:\n",
    "                run_clusters.append([])\n",
    "                index = run_clusters.index(run_cluster)\n",
    "                counts[index] += 1\n",
    "                \n",
    "        high_count_index = max(counts, key=counts.get)\n",
    "        return high_count_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBF:\n",
    "    \"\"\" Class that performs Radial Basis Functions (RBF) classification using pseudo-inverse algorithm. \"\"\"\n",
    "    \n",
    "    def __init__(self, gamma=1.0, K=3):\n",
    "        \"\"\" Create a Radial Basis Functions Algorithm (RBF). \n",
    "        Args:\n",
    "        gamma (float): Constant in the RBF kernel\n",
    "        K (int): Number of clusters\n",
    "        \"\"\"\n",
    "        self.gamma = gamma\n",
    "        self.K = K\n",
    "    \n",
    "    def fit(self, inputs, outputs):\n",
    "        \"\"\" Fit the training data using Lloyds algorithm + RBF pseudo-inverse learning algorithm. \n",
    "        Args:\n",
    "        inputs (np.ndarray): Inputs.\n",
    "        outputs (np.ndarray): Outputs\n",
    "        Returns Tuple(np.ndarray, np.ndarray): Weights and cluster centroids\n",
    "        \"\"\"\n",
    "        x = inputs\n",
    "        y = outputs\n",
    "        N = len(x)\n",
    "        \n",
    "        # cluster the inputs to obtain centroids mu\n",
    "        mu, labels = KKMeans.fit(inputs, self.K)\n",
    "        if np.size(mu) == 0:\n",
    "            return (np.array([]), np.array([]))\n",
    "        \n",
    "        # construct phi matrix\n",
    "        phi = []\n",
    "        for row_idx in range(0, N):\n",
    "            for col_idx in range(0, self.K):\n",
    "                kernel = self.kernel_rbf(x[row_idx], mu[col_idx])\n",
    "                phi.append(kernel)\n",
    "        phi = np.array(phi).reshape((N, self.K))\n",
    "        \n",
    "        # pseudo-inverse solution\n",
    "        phi_trans = np.transpose(phi)\n",
    "        norm_phi = np.matmul(phi_trans, phi)  \n",
    "        weights = np.matmul(np.linalg.inv(norm_phi), np.matmul(phi_trans, y))\n",
    "        \n",
    "        return weights, mu\n",
    "    \n",
    "    def binary_error(self, weights, centroids, inputs, outputs):\n",
    "        \"\"\" Evaluate binary classification error. \n",
    "        Args:\n",
    "        weights (np.ndarray): Weights.\n",
    "        centroids (np.ndarray): Centroids of clusters\n",
    "        inputs (np.ndarray): Inputs.\n",
    "        outputs (np.ndarray): Outputs.\n",
    "        Returns (float): Binary classification error percentage\n",
    "        \"\"\"\n",
    "        x = inputs\n",
    "        y = outputs\n",
    "        N = len(x)\n",
    "        mu = centroids\n",
    "        \n",
    "        # construct phi matrix\n",
    "        phi = []\n",
    "        for row_idx in range(0, N):\n",
    "            for col_idx in range(0, self.K):\n",
    "                kernel = self.kernel_rbf(x[row_idx], mu[col_idx])\n",
    "                phi.append(kernel)\n",
    "        phi = np.array(phi).reshape((N, self.K))\n",
    "        \n",
    "        # construct predictions and error percentage\n",
    "        signal = np.matmul(phi, weights)\n",
    "        g = np.sign(signal)\n",
    "        return 100. * np.sum(y != g) / len(y)   \n",
    "        \n",
    "    # privates\n",
    "    def kernel_rbf(self, xn, muk):\n",
    "        return np.exp(-self.gamma * (np.linalg.norm(xn - muk)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare regular RBF with kernel form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regular_kernel_trials(N=100, n_trials=100, K=9, gamma=1.5):\n",
    "    \n",
    "    non_sep_count = 0\n",
    "    empty_cluster_count = 0\n",
    "    wins_svm = 0\n",
    "    \n",
    "    for n_trial in range(0, n_trials):\n",
    "        # generate training data\n",
    "        train_inputs = generate_training_inputs(N)\n",
    "        train_outputs = compute_targets(train_inputs)\n",
    "        \n",
    "        # run SVM\n",
    "        svm = SVM(kernel='rbf', gamma=gamma)\n",
    "        alphas, sv, sv_outputs, b = svm.fit(train_inputs, train_outputs)\n",
    "        \n",
    "        # check if non-separable\n",
    "        ein = svm.binary_error(alphas, sv, sv_outputs, b, train_inputs, train_outputs)\n",
    "        if ein > 0.0:\n",
    "            non_sep_count += 1\n",
    "            continue\n",
    "        \n",
    "        # run regular RBF\n",
    "        rbf = RBF(gamma, K)\n",
    "        weights, centroids = rbf.fit(train_inputs, train_outputs)\n",
    "        \n",
    "        # check if empty clusters\n",
    "        if np.size(weights) == 0:\n",
    "            empty_cluster_count += 1\n",
    "            continue\n",
    "        \n",
    "        # generate out of sample data\n",
    "        test_inputs = generate_training_inputs(N*10)\n",
    "        test_outputs = compute_targets(test_inputs)\n",
    "        \n",
    "        # compute and compare out of sample errors\n",
    "        eout_svm = svm.binary_error(alphas, sv, sv_outputs, b, test_inputs, test_outputs)\n",
    "        eout_rbf = rbf.binary_error(weights, centroids, test_inputs, test_outputs) \n",
    "        \n",
    "        if eout_svm < eout_rbf:\n",
    "            wins_svm +=1\n",
    "            \n",
    "    win_percent = 100. * wins_svm / (n_trials - non_sep_count - empty_cluster_count)\n",
    "    return (win_percent, non_sep_count, empty_cluster_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare regular RBF for different parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_reg_rbf_param_trials(N=100, n_trials=100, Ks=[9], gammas=[1.5]):\n",
    "    \n",
    "    empty_cluster_count = 0\n",
    "    ein_down_eout_up = 0\n",
    "    ein_up_eout_down = 0\n",
    "    both_up = 0\n",
    "    both_down = 0\n",
    "    both_same = 0\n",
    "    \n",
    "    for n_trial in range(0, n_trials):\n",
    "        eins = []\n",
    "        eouts = []\n",
    "        for K in Ks:\n",
    "            for gamma in gammas:\n",
    "                \n",
    "                # generate training data\n",
    "                train_inputs = generate_training_inputs(N)\n",
    "                train_outputs = compute_targets(train_inputs)\n",
    "\n",
    "                # run regular RBF\n",
    "                rbf = RBF(gamma, K)\n",
    "                weights, centroids = rbf.fit(train_inputs, train_outputs)\n",
    "\n",
    "                # check if empty clusters\n",
    "                if np.size(weights) == 0:\n",
    "                    empty_cluster_count += 1\n",
    "                    continue\n",
    "\n",
    "                # generate out of sample data\n",
    "                test_inputs = generate_training_inputs(N*10)\n",
    "                test_outputs = compute_targets(test_inputs)\n",
    "\n",
    "                # compute and compare values of in and out of sample errors\n",
    "                ein = rbf.binary_error(weights, centroids, train_inputs, train_outputs) \n",
    "                eout = rbf.binary_error(weights, centroids, test_inputs, test_outputs) \n",
    "                \n",
    "                eins.append(ein)\n",
    "                eouts.append(eout)\n",
    "        \n",
    "        # skip comparisons if empty cluster\n",
    "        if len(eins) < 2 or len(eouts) < 2:\n",
    "            continue\n",
    "        \n",
    "        # perform comparisons for Ein and Eout\n",
    "        if (eins[1] > eins[0]) and (eouts[1] > eouts[0]):\n",
    "            both_up += 1\n",
    "        elif (eins[1] < eins[0]) and (eouts[1] < eouts[0]):\n",
    "            both_down += 1\n",
    "        elif (eins[1] > eins[0]) and (eouts[1] < eouts[0]):\n",
    "            ein_up_eout_down += 1\n",
    "        elif (eins[1] < eins[0]) and (eouts[1] > eouts[0]):\n",
    "            ein_down_eout_up += 1\n",
    "        else:\n",
    "            both_same += 1\n",
    "    \n",
    "    counts = {'Ein goes down, but Eout goes up': ein_down_eout_up,\n",
    "              'Ein goes up, but Eout goes down ': ein_up_eout_down,\n",
    "              'Both Ein and Eout go up': both_up,\n",
    "              'Both Ein and Eout go down': both_down,\n",
    "              'Ein and Eout remain the same': both_same\n",
    "             }\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run regular RBF trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_reg_rbf_trials(N=100, n_trials=100, K=9, gamma=1.5):\n",
    "    \n",
    "    empty_cluster_count = 0\n",
    "    ein_zero_count = 0\n",
    "    \n",
    "    for n_trial in range(0, n_trials):\n",
    "        # generate training data\n",
    "        train_inputs = generate_training_inputs(N)\n",
    "        train_outputs = compute_targets(train_inputs)\n",
    "        \n",
    "        # run regular RBF\n",
    "        rbf = RBF(gamma, K)\n",
    "        weights, centroids = rbf.fit(train_inputs, train_outputs)\n",
    "        \n",
    "        # check if empty clusters\n",
    "        if np.size(weights) == 0:\n",
    "            empty_cluster_count += 1\n",
    "            continue\n",
    "        \n",
    "        # compute in sample error\n",
    "        ein = rbf.binary_error(weights, centroids, train_inputs, train_outputs) \n",
    "        \n",
    "        if ein == 0.0:\n",
    "            ein_zero_count +=1\n",
    "            \n",
    "    ein_zero_percent = 100. * ein_zero_count / (n_trials - empty_cluster_count)\n",
    "    return (ein_zero_percent, empty_cluster_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data set is not separable by the RBF kernel 0.0% of the time in 100 runs.\n"
     ]
    }
   ],
   "source": [
    "n_trials=100\n",
    "non_sep_percent = run_svm_trials(100, n_trials)\n",
    "print(\"The data set is not separable by the RBF kernel {0}% of the time in {1} runs.\"\n",
    "      .format(round(non_sep_percent, 2), n_trials))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For K = 9 and γ = 1.5 the kernel form beats the regular form 86.17% of the time in 94 runs (0 runs not separable, 6 runs with empty clusters).\n"
     ]
    }
   ],
   "source": [
    "n_trials = 100\n",
    "K = 9\n",
    "gamma = 1.5\n",
    "win_percent, non_sep_count, empty_cluster_count = run_regular_kernel_trials(100, n_trials, K, gamma)\n",
    "print(\"For K = {0} and γ = {1} the kernel form beats the regular form {2}% of the time in {3} runs ({4} runs not separable, \"\n",
    "      \"{5} runs with empty clusters).\"\n",
    "      .format(K, gamma, round(win_percent, 2), n_trials - non_sep_count - empty_cluster_count, non_sep_count, empty_cluster_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For K = 12 and γ = 1.5 the kernel form beats the regular form 73.26% of the time in 86 runs (0 runs not separable, 14 runs with empty clusters).\n"
     ]
    }
   ],
   "source": [
    "n_trials = 100\n",
    "K = 12\n",
    "gamma = 1.5\n",
    "win_percent, non_sep_count, empty_cluster_count = run_regular_kernel_trials(100, n_trials, K, gamma)\n",
    "print(\"For K = {0} and γ = {1} the kernel form beats the regular form {2}% of the time in {3} runs ({4} runs not separable, \"\n",
    "      \"{5} runs with empty clusters).\"\n",
    "      .format(K, gamma, round(win_percent, 2), n_trials - non_sep_count - empty_cluster_count, non_sep_count, empty_cluster_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For regular RBF with γ = 1.5. If we go from K = 9 clusters to K = 12 clusters then 'Both Ein and Eout go down' happens the most (22 times) (excluding runs with empty clusters).\n"
     ]
    }
   ],
   "source": [
    "n_trials = 100\n",
    "Ks=[9, 12]\n",
    "gammas=[1.5]\n",
    "counts = run_reg_rbf_param_trials(100, n_trials, Ks, gammas)\n",
    "max_counts = max(counts, key=counts.get)\n",
    "print(\"For regular RBF with γ = {0}. If we go from K = {1} clusters to K = {2} clusters then '{3}' happens the most ({4} times)\"\n",
    "      \" (excluding runs with empty clusters).\"\n",
    "      .format(gammas[0], Ks[0], Ks[1], max_counts, counts[max_counts]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For regular RBF with K = 9 clusters. If we go from γ = 1.5 clusters to γ = 2.0 clusters then 'Both Ein and Eout go up' happens the most (28 times) (excluding runs with empty clusters).\n"
     ]
    }
   ],
   "source": [
    "n_trials = 100\n",
    "Ks=[9]\n",
    "gammas=[1.5, 2.0]\n",
    "counts = run_reg_rbf_param_trials(100, n_trials, Ks, gammas)\n",
    "max_counts = max(counts, key=counts.get)\n",
    "print(\"For regular RBF with K = {0} clusters. If we go from γ = {1} clusters to γ = {2} clusters then '{3}' happens the most\"\n",
    "      \" ({4} times) (excluding runs with empty clusters).\"\n",
    "      .format(Ks[0], gammas[0], gammas[1], max_counts, counts[max_counts]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regular RBF achives Ein = 0 with K = 9 and γ = 1.5, 1.09% of the time (excluding 8 runs with empty clusters).\n"
     ]
    }
   ],
   "source": [
    "n_trials = 100\n",
    "K = 9\n",
    "gamma = 1.5\n",
    "ein_zero_percent, empty_cluster_count = run_reg_rbf_trials(100, n_trials, K, gamma)\n",
    "print(\"The regular RBF achives Ein = 0 with K = {0} and γ = {1}, {2}% of the time (excluding {3} runs with empty clusters).\"\n",
    "      .format(K, gamma, round(ein_zero_percent, 2), empty_cluster_count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
